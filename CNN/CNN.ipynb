{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "import os, os.path\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "from plyfile import PlyData, PlyElement\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    height = conv_ksize[0]\n",
    "    width = conv_ksize[1]\n",
    "    F_W = tf.Variable(tf.truncated_normal([height, width, x_tensor.shape.as_list()[3], conv_num_outputs],stddev=0.01))# (height, width, input_depth, output_depth)\n",
    "    F_b = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conLayer = tf.nn.conv2d(x_tensor, F_W, strides=[1,conv_strides[0], conv_strides[1],1], padding='SAME')\n",
    "    conLayer = tf.nn.bias_add(conLayer, F_b)\n",
    "    conLayer = tf.nn.relu(conLayer)\n",
    "    return tf.nn.max_pool(conLayer, ksize=[1,pool_ksize[0],pool_ksize[1],1], strides=[1,pool_strides[0], pool_strides[1],1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "\n",
    "    return tf.placeholder(tf.float32, shape=(None,image_shape[0],image_shape[1],image_shape[2]),name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "\n",
    "    return tf.placeholder(tf.float32,shape=(None,n_classes),name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "\n",
    "    return tf.placeholder(tf.float32, shape=None, name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-e270ca0ca23c>:34: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "\n",
    "    pool1 = conv2d_maxpool(x, 64, [3,3], [1,1], [8,8], [1,1])\n",
    "    pool2 = conv2d_maxpool(pool1, 28, [3,3], [1,1], [5,5], [1,1])\n",
    "    pool2 = tf.nn.dropout(pool2, keep_prob)\n",
    "    \n",
    "    flat = tf.contrib.layers.flatten(pool2)\n",
    "\n",
    "    layer3 = tf.contrib.layers.fully_connected(flat,1024)\n",
    "    layer4 = tf.contrib.layers.fully_connected(layer3,1024)\n",
    "    layer4 = tf.nn.dropout(layer4, keep_prob)\n",
    "    \n",
    "    #Apply an Output Layer\n",
    "    out = tf.contrib.layers.fully_connected(layer4,32,activation_fn=None)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((64, 64, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_net(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x : feature_batch,\n",
    "        y : label_batch,\n",
    "        keep_prob : keep_probability\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
